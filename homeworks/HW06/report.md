# HW06 – Report

## 1. Dataset

- Выбранный датасет:    `S06-hw-dataset-04.csv`
- Размер:                25000 строк, 62 столбцов (числовые признаки).
- Целевая переменная:   `target`. Наблюдается сильный дисбаланс классов: 
                        - класс 0 — ~ 95.1 %, 
                        - класс 1 — ~ 4.9%.
- Признаки:             Все признаки числовые (`float64`), пропусков нет. Это позволяет использовать большинство моделей без сложной предобработки (кроме масштабирования для линейных моделей).

## 2. Protocol

- Разбиение:            Train/Test в соотношении 75/25 (`test_size=0.25`)
                        - Train: 18 750 строк.
                        - Test: 6 250 строк.
- Воспроизводимость:    Зафиксирован `random_state=42`.
- Стратификация:        Использована `stratify=y` чтобы в тесте и трейне сохранилась доля редкого класса (5%).
- Подбор:               GridSearchCV на train выборке с 5 фолдами (cv=5), оптимизировали метрику `ROC-AUC`.
- Метрики:
                        - ROC-AUC: Основная метрика. При дисбалансе 95/5 `Accuracy` бесполезна (Dummy дает 95%), поэтому оцениваем способность модели ранжировать объекты.
                        - F1-score: Важна для оценки точности на редком классе.

## 3. Models

Были обучены и сравнены следующие модели:

1.  DummyClassifier (Baseline):     Стратегия `most_frequent`. Служит нижней границей качества.
2.  LogisticRegression (Baseline):  Простая линейная модель с L2-регуляризацией. Обучалась через Pipeline с `StandardScaler`.
3.  DecisionTreeClassifier:
                                    - Подбор глубины и min_samples_leaf.
                                    - Использовался параметр `class_weight='balanced'`, чтобы штрафовать за ошибки на редком классе.
4.  RandomForestClassifier:
                                    - Ансамбль (бэггинг) деревьев.
                                    - Также использовался `class_weight='balanced'`.
5.  GradientBoostingClassifier:
                                    - Бустинг над деревьями.

## 4. Results

Итоговые метрики на отложенной тестовой выборке:


| Модель             | Accuracy |    F1    | ROC-AUC  |
|--------------------|----------|--------  |--------- |
| RandomForest       |  0.9710  |  0.5820  |  0.9100  |
| GradientBoosting   |  0.9714	|  0.6775  |  0.8926  |
| LogisticRegression |  0.9627	|  0.4131  |  0.8397  |
| DecisionTree       |  0.8800	|  0.3729  |  0.8254  |
| Dummy              |  0.9509	|  0.0000  |  0.5000  |

Лучший результат по ROC-AUC показала модель RandomForest. Она лучше всего уловила сложные зависимости в данных, несмотря на дисбаланс.

## 5. Analysis

- Устойчивость:
    Так как стандартное отклонение крайне мало (меньше 0.01), можно утверждать, что модель устойчива. Полученные метрики не являются результатом удачного или неудачного случайного разбиения, а отражают реальную предсказательную способность алгоритма на этих данных.
- Ошибки:
    Из-за параметра `class_weight='balanced'` модели (особенно лес) могут давать больше ложных срабатываний (False Positive), но зато они находят больше реальных объектов класса 1, что критически важно при таком дисбалансе.
- Интерпретация (Permutation Importance):
    Согласно графику, наиболее важными признаками для предсказания класса 1 являются:
    1. f58 (с большим отрывом)
    2. f53
    3. f13
    4. f47
    Многие другие признаки (например, f16, f04) имеют почти нулевое влияние. Их можно было бы удалить для упрощения модели.


## 6. Conclusion

1.  Высокая Accuracy (95%) у Dummy-модели ничего не значит. F1-score = 0 показывает, что она вообще не находит целевой класс.
2.  LogisticRegression дала хороший старт (0.84 AUC), но ансамбли (Лес/Бустинг) смогли улучшить этот результат за счет нахождения нелинейных зависимостей между признаками `f58` и другими.
3.  Задача сильно зависит от конкретных признаков (f58, f53). Если бы мы их убрали, качество упало бы значительно.